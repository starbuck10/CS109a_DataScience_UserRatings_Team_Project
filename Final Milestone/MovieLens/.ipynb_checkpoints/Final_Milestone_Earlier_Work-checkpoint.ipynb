{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EUCLIDEAN = 'euclidean'\n",
    "MANHATTAN = 'manhattan'\n",
    "PEARSON = 'pearson'\n",
    "\n",
    "\n",
    "def read_ratings_df():\n",
    "    date_parser = lambda time_in_secs: datetime.utcfromtimestamp(float(time_in_secs))\n",
    "    return pd.read_csv('ml-latest-small/ratings.csv', parse_dates=['timestamp'], date_parser=date_parser)\n",
    "\n",
    "\n",
    "class MovieData(object):\n",
    "    def __init__(self):\n",
    "        self.ratings_df = read_ratings_df()\n",
    "        self.ratings = defaultdict(dict)\n",
    "        self.init_ratings()\n",
    "\n",
    "    def init_ratings(self):\n",
    "        for _, row in self.ratings_df.iterrows():\n",
    "            self.ratings[row['userId']][row['movieId']] = row\n",
    "\n",
    "    def get_movies(self, user_id):\n",
    "        return set(self.ratings[user_id].keys())\n",
    "\n",
    "    def get_unique_user_ids(self):\n",
    "        return self.ratings_df['userId'].unique()\n",
    "\n",
    "    def get_shared_ratings(self, user1_id, user2_id):\n",
    "        movies1 = self.get_movies(user1_id)\n",
    "        movies2 = self.get_movies(user2_id)\n",
    "\n",
    "        shared_movies = movies1 & movies2\n",
    "\n",
    "        ratings = {}\n",
    "\n",
    "        for movie_id in shared_movies:\n",
    "            ratings[movie_id] = (\n",
    "                self.ratings[user1_id][movie_id]['rating'],\n",
    "                self.ratings[user2_id][movie_id]['rating'],\n",
    "            )\n",
    "\n",
    "        return ratings\n",
    "\n",
    "    @staticmethod\n",
    "    def shared_ratings_to_np_arrays(shared_ratings):\n",
    "        return np.array(shared_ratings.values()).T\n",
    "\n",
    "    def get_euclidean_distance(self, user1_id, user2_id):\n",
    "        shared_ratings = self.get_shared_ratings(user1_id, user2_id)\n",
    "\n",
    "        if len(shared_ratings) == 0:\n",
    "            return 0\n",
    "\n",
    "        ratings = self.shared_ratings_to_np_arrays(shared_ratings)\n",
    "\n",
    "        ratings1 = ratings[0]\n",
    "        ratings2 = ratings[1]\n",
    "\n",
    "        sum_of_squares = np.power(ratings1 - ratings2, 2).sum()\n",
    "\n",
    "        return 1 / (1 + sqrt(sum_of_squares))\n",
    "\n",
    "    def get_manhattan_distance(self, user1_id, user2_id):\n",
    "        shared_ratings = self.get_shared_ratings(user1_id, user2_id)\n",
    "\n",
    "        if len(shared_ratings) == 0:\n",
    "            return 0\n",
    "\n",
    "        ratings = self.shared_ratings_to_np_arrays(shared_ratings)\n",
    "\n",
    "        ratings1 = ratings[0]\n",
    "        ratings2 = ratings[1]\n",
    "\n",
    "        manhattan_sum = np.abs(ratings1 - ratings2).sum()\n",
    "\n",
    "        return 1 / (1 + manhattan_sum)\n",
    "\n",
    "    def get_pearson_correlation(self, user1_id, user2_id):\n",
    "        shared_ratings = self.get_shared_ratings(user1_id, user2_id)\n",
    "\n",
    "        num_ratings = len(shared_ratings)\n",
    "\n",
    "        if num_ratings == 0:\n",
    "            return 0\n",
    "\n",
    "        ratings = self.shared_ratings_to_np_arrays(shared_ratings)\n",
    "\n",
    "        ratings1 = ratings[0]\n",
    "        ratings2 = ratings[1]\n",
    "\n",
    "        mean1 = ratings1.mean()\n",
    "        mean2 = ratings2.mean()\n",
    "\n",
    "        std1 = ratings1.std()\n",
    "        std2 = ratings2.std()\n",
    "\n",
    "        if std1 == 0 or std2 == 0:\n",
    "            return 0\n",
    "\n",
    "        std_scores_1 = (ratings1 - mean1) / std1\n",
    "        std_scores_2 = (ratings2 - mean2) / std2\n",
    "\n",
    "        # numerically stable calculation of the Pearson correlation coefficient\n",
    "\n",
    "        return abs((std_scores_1 * std_scores_2).sum() / (num_ratings - 1))\n",
    "\n",
    "    def get_similar_users(self, user_id, metric=EUCLIDEAN):\n",
    "        metrics = {\n",
    "            EUCLIDEAN: self.get_euclidean_distance,\n",
    "            MANHATTAN: self.get_manhattan_distance,\n",
    "            PEARSON: self.get_pearson_correlation,\n",
    "        }\n",
    "\n",
    "        distance_f = metrics[metric]\n",
    "\n",
    "        similar_users = {}\n",
    "\n",
    "        for similar_user_id in self.ratings:\n",
    "            if similar_user_id == user_id:\n",
    "                continue\n",
    "            distance = distance_f(user_id, similar_user_id)\n",
    "            if distance > 0:\n",
    "                similar_users[similar_user_id] = distance\n",
    "\n",
    "        return similar_users\n",
    "\n",
    "    def predict_score(self, user_id, movie_id):\n",
    "        similar_users = self.get_similar_users(user_id)\n",
    "\n",
    "        total_rating_sum = 0\n",
    "        similarity_sum = 0\n",
    "\n",
    "        for similar_user_id, similarity in similar_users.items():\n",
    "            user_ratings = self.ratings[similar_user_id]\n",
    "            if movie_id in user_ratings:\n",
    "                total_rating_sum += similarity * user_ratings[movie_id]['rating']\n",
    "                similarity_sum += similarity\n",
    "\n",
    "        if similarity_sum == 0:\n",
    "            return 0\n",
    "\n",
    "        return total_rating_sum / similarity_sum\n",
    "\n",
    "        \n",
    "movie_data = MovieData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore shared ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair  1, user1 movies:  111, user2 movies:  485, shared movies:  28\n",
      "pair  2, user1 movies:   21, user2 movies:   20, shared movies:   0\n",
      "pair  3, user1 movies:   63, user2 movies:   23, shared movies:   5\n",
      "pair  4, user1 movies:  483, user2 movies:  159, shared movies:  87\n",
      "pair  5, user1 movies:   22, user2 movies:   72, shared movies:   3\n",
      "pair  6, user1 movies:   50, user2 movies:   20, shared movies:   0\n",
      "pair  7, user1 movies:   22, user2 movies:  385, shared movies:   7\n",
      "pair  8, user1 movies:  263, user2 movies:  129, shared movies:  26\n",
      "pair  9, user1 movies:  300, user2 movies:   22, shared movies:   7\n",
      "pair 10, user1 movies:   38, user2 movies:   61, shared movies:   0\n",
      "pair 11, user1 movies:   87, user2 movies:   36, shared movies:   2\n",
      "pair 12, user1 movies:  427, user2 movies:   79, shared movies:  31\n",
      "pair 13, user1 movies:   20, user2 movies:  522, shared movies:   6\n",
      "pair 14, user1 movies:  114, user2 movies:   87, shared movies:  14\n",
      "pair 15, user1 movies:   28, user2 movies:   51, shared movies:   1\n",
      "pair 16, user1 movies:  215, user2 movies:  223, shared movies:  26\n",
      "pair 17, user1 movies:  713, user2 movies:   44, shared movies:  19\n",
      "pair 18, user1 movies:   82, user2 movies:   21, shared movies:   2\n",
      "pair 19, user1 movies:   73, user2 movies:   59, shared movies:   7\n",
      "pair 20, user1 movies:  617, user2 movies:  255, shared movies:  98\n",
      "pair 21, user1 movies:  138, user2 movies:   99, shared movies:   2\n",
      "pair 22, user1 movies:   99, user2 movies:   28, shared movies:   3\n",
      "pair 23, user1 movies:   24, user2 movies:  155, shared movies:   2\n",
      "pair 24, user1 movies:  291, user2 movies:   25, shared movies:   0\n",
      "pair 25, user1 movies:  617, user2 movies:  205, shared movies:  92\n",
      "pair 26, user1 movies:  100, user2 movies:   31, shared movies:   8\n",
      "pair 27, user1 movies:   91, user2 movies:   26, shared movies:   2\n",
      "pair 28, user1 movies:  487, user2 movies:   51, shared movies:  20\n",
      "pair 29, user1 movies:   26, user2 movies:  133, shared movies:   1\n",
      "pair 30, user1 movies: 1291, user2 movies:  194, shared movies: 126\n"
     ]
    }
   ],
   "source": [
    "def explore_shared_ratings(movie_data):\n",
    "    unique_user_ids = movie_data.get_unique_user_ids()\n",
    "\n",
    "    n_pairs = 30\n",
    "    samples = np.random.choice(unique_user_ids, size=(n_pairs, 2))\n",
    "\n",
    "    for index, sample in enumerate(samples):\n",
    "        user1_id = sample[0]\n",
    "        user2_id = sample[1]\n",
    "\n",
    "        num_movies_1 = len(movie_data.get_movies(user1_id))\n",
    "        num_movies_2 = len(movie_data.get_movies(user2_id))\n",
    "\n",
    "        num_shared_ratings = len(movie_data.get_shared_ratings(user1_id, user2_id))\n",
    "\n",
    "        print 'pair %2d, user1 movies: %4d, user2 movies: %4d, shared movies: %3d' % (\n",
    "            index + 1, num_movies_1, num_movies_2, num_shared_ratings)\n",
    "\n",
    "        \n",
    "explore_shared_ratings(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking at 30 random user pairs. We can notice how small on average is the intersection of the movies they rated (compared to the their total number of ratings).\n",
    "It's not unusual to see zero intersection or just a couple of movies.\n",
    "\n",
    "We could build a histogram of the distribution of number of shared movies if we generate a lot of random pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair  1, shared movies:  65, euclidean: 0.098, manhattan: 0.018, pearson: 0.210\n",
      "pair  2, shared movies:   0, euclidean: 0.000, manhattan: 0.000, pearson: 0.000\n",
      "pair  3, shared movies:  49, euclidean: 0.112, manhattan: 0.024, pearson: 0.201\n",
      "pair  4, shared movies:   8, euclidean: 0.152, manhattan: 0.083, pearson: 0.123\n",
      "pair  5, shared movies:   1, euclidean: 0.400, manhattan: 0.400, pearson: 0.000\n",
      "pair  6, shared movies:   0, euclidean: 0.000, manhattan: 0.000, pearson: 0.000\n",
      "pair  7, shared movies:   0, euclidean: 0.000, manhattan: 0.000, pearson: 0.000\n",
      "pair  8, shared movies:   6, euclidean: 0.200, manhattan: 0.111, pearson: 0.100\n",
      "pair  9, shared movies: 108, euclidean: 0.053, manhattan: 0.006, pearson: 0.088\n",
      "pair 10, shared movies:  27, euclidean: 0.121, manhattan: 0.031, pearson: 0.023\n",
      "pair 11, shared movies:  29, euclidean: 0.131, manhattan: 0.035, pearson: 0.257\n",
      "pair 12, shared movies:   7, euclidean: 0.232, manhattan: 0.125, pearson: 0.490\n",
      "pair 13, shared movies:   1, euclidean: 0.333, manhattan: 0.333, pearson: 0.000\n",
      "pair 14, shared movies:  12, euclidean: 0.081, manhattan: 0.026, pearson: 0.250\n",
      "pair 15, shared movies:  11, euclidean: 0.240, manhattan: 0.111, pearson: 0.289\n",
      "pair 16, shared movies:   0, euclidean: 0.000, manhattan: 0.000, pearson: 0.000\n",
      "pair 17, shared movies:   7, euclidean: 0.240, manhattan: 0.200, pearson: 0.269\n",
      "pair 18, shared movies:   1, euclidean: 0.500, manhattan: 0.500, pearson: 0.000\n",
      "pair 19, shared movies:   2, euclidean: 0.271, manhattan: 0.222, pearson: 2.000\n",
      "pair 20, shared movies:   2, euclidean: 0.667, manhattan: 0.667, pearson: 2.000\n",
      "pair 21, shared movies:   5, euclidean: 0.327, manhattan: 0.222, pearson: 0.859\n",
      "pair 22, shared movies:   7, euclidean: 0.194, manhattan: 0.095, pearson: 0.776\n",
      "pair 23, shared movies:   0, euclidean: 0.000, manhattan: 0.000, pearson: 0.000\n",
      "pair 24, shared movies:  24, euclidean: 0.131, manhattan: 0.037, pearson: 0.324\n",
      "pair 25, shared movies:  67, euclidean: 0.099, manhattan: 0.018, pearson: 0.304\n",
      "pair 26, shared movies:   2, euclidean: 0.387, manhattan: 0.333, pearson: 0.000\n",
      "pair 27, shared movies:  38, euclidean: 0.203, manhattan: 0.050, pearson: 0.565\n",
      "pair 28, shared movies:   3, euclidean: 0.250, manhattan: 0.167, pearson: 0.750\n",
      "pair 29, shared movies:   7, euclidean: 0.286, manhattan: 0.154, pearson: 0.297\n",
      "pair 30, shared movies:   9, euclidean: 0.152, manhattan: 0.077, pearson: 0.025\n"
     ]
    }
   ],
   "source": [
    "def explore_distances(movie_data):\n",
    "    unique_user_ids = movie_data.get_unique_user_ids()\n",
    "\n",
    "    n_pairs = 30\n",
    "    samples = np.random.choice(unique_user_ids, size=(n_pairs, 2))\n",
    "\n",
    "    for index, sample in enumerate(samples):\n",
    "        user1_id = sample[0]\n",
    "        user2_id = sample[1]\n",
    "\n",
    "        num_shared_ratings = len(movie_data.get_shared_ratings(user1_id, user2_id))\n",
    "\n",
    "        euclidean_distance = movie_data.get_euclidean_distance(user1_id, user2_id)\n",
    "        manhattan_distance = movie_data.get_manhattan_distance(user1_id, user2_id)\n",
    "        pearson_correlation = movie_data.get_pearson_correlation(user1_id, user2_id)\n",
    "\n",
    "        print 'pair %2d, shared movies: %3d, euclidean: %.3f, manhattan: %.3f, pearson: %.3f' % (\n",
    "            index + 1, num_shared_ratings, euclidean_distance, manhattan_distance, pearson_correlation)\n",
    "\n",
    "        \n",
    "explore_distances(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various distances (euclidean, manhattan, pearson correlation).\n",
    "\n",
    "Other possible distances: Tantimoto, cosine.\n",
    "\n",
    "Jaccard distance is not really applicable in this case since we have a range of ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user   1, similar users: 507, max similarity: 1.000, mean: 0.401, std: 0.219\n",
      "user   2, similar users: 664, max similarity: 1.000, mean: 0.191, std: 0.114\n",
      "user   3, similar users: 668, max similarity: 1.000, mean: 0.202, std: 0.126\n",
      "user   4, similar users: 665, max similarity: 1.000, mean: 0.145, std: 0.108\n",
      "user   5, similar users: 670, max similarity: 1.000, mean: 0.156, std: 0.090\n",
      "user   6, similar users: 600, max similarity: 1.000, mean: 0.280, std: 0.197\n",
      "user   7, similar users: 406, max similarity: 1.000, mean: 0.378, std: 0.221\n",
      "user   8, similar users: 653, max similarity: 1.000, mean: 0.262, std: 0.165\n",
      "user   9, similar users: 647, max similarity: 1.000, mean: 0.245, std: 0.139\n",
      "user  10, similar users: 658, max similarity: 1.000, mean: 0.239, std: 0.145\n",
      "user  11, similar users: 670, max similarity: 0.348, mean: 0.115, std: 0.055\n",
      "user  12, similar users: 530, max similarity: 1.000, mean: 0.354, std: 0.187\n",
      "user  13, similar users: 593, max similarity: 1.000, mean: 0.346, std: 0.224\n",
      "user  14, similar users: 342, max similarity: 1.000, mean: 0.412, std: 0.197\n",
      "user  15, similar users: 493, max similarity: 1.000, mean: 0.448, std: 0.263\n",
      "user  16, similar users: 654, max similarity: 1.000, mean: 0.237, std: 0.140\n",
      "user  17, similar users: 652, max similarity: 1.000, mean: 0.285, std: 0.166\n",
      "user  18, similar users: 601, max similarity: 1.000, mean: 0.263, std: 0.194\n",
      "user  19, similar users: 638, max similarity: 1.000, mean: 0.267, std: 0.163\n",
      "user  20, similar users: 467, max similarity: 1.000, mean: 0.305, std: 0.194\n",
      "user  21, similar users: 311, max similarity: 1.000, mean: 0.475, std: 0.248\n",
      "user  22, similar users: 644, max similarity: 1.000, mean: 0.278, std: 0.150\n",
      "user  23, similar users: 659, max similarity: 1.000, mean: 0.208, std: 0.141\n",
      "user  24, similar users: 667, max similarity: 1.000, mean: 0.137, std: 0.102\n",
      "user  25, similar users: 621, max similarity: 1.000, mean: 0.325, std: 0.159\n",
      "user  26, similar users: 652, max similarity: 1.000, mean: 0.261, std: 0.153\n",
      "user  27, similar users: 634, max similarity: 1.000, mean: 0.306, std: 0.150\n",
      "user  28, similar users: 556, max similarity: 1.000, mean: 0.425, std: 0.206\n",
      "user  29, similar users: 634, max similarity: 1.000, mean: 0.279, std: 0.166\n",
      "user  30, similar users: 628, max similarity: 1.000, mean: 0.264, std: 0.164\n"
     ]
    }
   ],
   "source": [
    "def explore_similar_users(movie_data):\n",
    "    unique_user_ids = movie_data.get_unique_user_ids()\n",
    "\n",
    "    n_users = 30\n",
    "    user_ids = np.random.choice(unique_user_ids, size=n_users, replace=False)\n",
    "\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        similar_users = movie_data.get_similar_users(user_id)\n",
    "\n",
    "        distances = similar_users.values()\n",
    "\n",
    "        print 'user %3d, similar users: %d, max similarity: %.3f, mean: %.3f, std: %.3f' % (\n",
    "            index + 1, len(similar_users), np.max(distances), np.mean(distances), np.std(distances))\n",
    "\n",
    "        \n",
    "explore_similar_users(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max similarity of 1.0 in most cases is probably an intersection of one movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore predict score (user similarity model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating  1, rating: 3.5, predicted: 3.908\n",
      "rating  2, rating: 5.0, predicted: 4.532\n",
      "rating  3, rating: 2.0, predicted: 3.670\n",
      "rating  4, rating: 3.0, predicted: 3.389\n",
      "rating  5, rating: 3.5, predicted: 3.541\n",
      "rating  6, rating: 4.0, predicted: 3.177\n",
      "rating  7, rating: 1.5, predicted: 3.747\n",
      "rating  8, rating: 5.0, predicted: 3.993\n",
      "rating  9, rating: 3.0, predicted: 3.329\n",
      "rating 10, rating: 2.0, predicted: 3.590\n",
      "rating 11, rating: 1.5, predicted: 3.154\n",
      "rating 12, rating: 4.0, predicted: 3.322\n",
      "rating 13, rating: 2.5, predicted: 2.950\n",
      "rating 14, rating: 2.5, predicted: 2.934\n",
      "rating 15, rating: 3.5, predicted: 0.000\n",
      "rating 16, rating: 4.5, predicted: 3.824\n",
      "rating 17, rating: 3.0, predicted: 3.453\n",
      "rating 18, rating: 4.0, predicted: 4.117\n",
      "rating 19, rating: 5.0, predicted: 3.971\n",
      "rating 20, rating: 1.0, predicted: 3.307\n",
      "rating 21, rating: 4.0, predicted: 3.485\n",
      "rating 22, rating: 4.0, predicted: 4.173\n",
      "rating 23, rating: 3.5, predicted: 3.815\n",
      "rating 24, rating: 4.0, predicted: 3.399\n",
      "rating 25, rating: 5.0, predicted: 4.134\n",
      "rating 26, rating: 2.0, predicted: 3.791\n",
      "rating 27, rating: 5.0, predicted: 3.858\n",
      "rating 28, rating: 4.5, predicted: 4.108\n",
      "rating 29, rating: 4.0, predicted: 3.758\n",
      "rating 30, rating: 5.0, predicted: 4.526\n"
     ]
    }
   ],
   "source": [
    "def explore_predict_score(movie_data):\n",
    "    ratings_df = movie_data.ratings_df\n",
    "    rating_indices = ratings_df.index\n",
    "\n",
    "    n_ratings = 30\n",
    "    sample = np.random.choice(rating_indices, size=n_ratings, replace=False)\n",
    "\n",
    "    for index, rating_index in enumerate(sample):\n",
    "        row = ratings_df.ix[rating_index]\n",
    "\n",
    "        user_id = row['userId']\n",
    "        movie_id = row['movieId']\n",
    "        rating = row['rating']\n",
    "\n",
    "        score = movie_data.predict_score(user_id, movie_id)\n",
    "\n",
    "        print 'rating %2d, rating: %.1f, predicted: %.3f' % (index + 1, rating, score)\n",
    "\n",
    "        \n",
    "explore_predict_score(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
